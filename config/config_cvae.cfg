[MODEL]
attn_mode = dot
hidden_size = 128
latent_size = 128
n_layers = 1
dropout = 0.5
batch_size = 128
clip = 50.0
teacher_forcing_ratio = 1.0
learning_rate = 0.001
decoder_learning_ratio = 1.0
shuffle = True
full_kl_step = 10000
word_dropout = 0.0

n_epochs = 50000
plot_every = 20
print_every = 100
evaluate_every = 1000
